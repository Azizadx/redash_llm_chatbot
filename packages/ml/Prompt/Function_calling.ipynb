{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is just a sample code so that you can understand how to use function calling it not a starter code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json \n",
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the example below LLM acts as an intermediary that translates a user's natural language request into a structured SQL query, which is then executed by a database tool to fetch and return the relevant data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gcp \n",
    "_SCOPE = 'https://www.googleapis.com/auth/cloud-platform'\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client.from_service_account_json('../../data_warehousing/data_warehousing/include/gcp/service_account.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if tools is not None:\n",
    "        json_data.update({\"tools\": tools})\n",
    "    if tool_choice is not None:\n",
    "        json_data.update({\"tool_choice\": tool_choice})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"tool\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"tool\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_table_names(client, dataset_id):\n",
    "    \"\"\"Return a list of table names in the specified dataset.\"\"\"\n",
    "    table_names = []\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    # List tables in the dataset\n",
    "    tables = client.list_tables(dataset_ref)\n",
    "    for table in tables:\n",
    "        table_names.append(table.table_id)\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(client, dataset_id, table_name):\n",
    "    \"\"\"Return a list of column names for the specified table.\"\"\"\n",
    "    column_names = []\n",
    "    table_ref = client.dataset(dataset_id).table(table_name)\n",
    "    table = client.get_table(table_ref)\n",
    "    for field in table.schema:\n",
    "        column_names.append(field.name)\n",
    "    return column_names\n",
    "\n",
    "def get_database_info(client, dataset_id):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the dataset.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(client, dataset_id):\n",
    "        column_names = get_column_names(client, dataset_id, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": column_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(client,'youtube')\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: dim_dail_view_7day\n",
      "Columns: Date, RollingAverageViews\n",
      "Table: dim_top10\n",
      "Columns: Date, TotalViews\n",
      "Table: raw_cities\n",
      "Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
      "Table: raw_gender\n",
      "Columns: Date, Views, Watch_time__hours_, Average_view_duration\n",
      "Table: raw_total\n",
      "Columns: Date, Views\n"
     ]
    }
   ],
   "source": [
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_database(client, query):\n",
    "    \"\"\"Function to query BigQuery dataset with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "        rows = [row.values() for row in results]\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "        rows = []\n",
    "    return rows\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"tool_calls\"][0][\"function\"][\"name\"] == \"ask_database\":\n",
    "        query = json.loads(message[\"tool_calls\"][0][\"function\"][\"arguments\"])[\"query\"]\n",
    "        results = ask_database(client, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message['tool_calls'][0]['function']['name']} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== {'id': 'chatcmpl-8db0ZHwTV1EkUkZA9LEurHwV3tsIk', 'object': 'chat.completion', 'created': 1704447743, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'call_BGFqgm95Jrw9ILQpYElvXHGB', 'type': 'function', 'function': {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT DISTINCT City_name FROM raw_cities\"\\n}'}}]}, 'logprobs': None, 'finish_reason': 'tool_calls'}], 'usage': {'prompt_tokens': 216, 'completion_tokens': 22, 'total_tokens': 238}, 'system_fingerprint': None}\n",
      "=================== {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT DISTINCT City_name FROM raw_cities\"\\n}'}\n",
      "\u001b[31msystem: Answer user questions by generating SQL queries against the youtube analytic Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, show me all cities?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT DISTINCT City_name FROM raw_cities\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Answer user questions by generating SQL queries against the youtube analytic Database.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Hi, show me all cities?\"})\n",
    "\n",
    "# Assuming chat_completion_request returns a response with tool calls\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "print(\"===================\", chat_response.json())\n",
    "\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "assistant_message['content'] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "print(\"===================\", assistant_message['content'])\n",
    "\n",
    "messages.append(assistant_message)\n",
    "\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'],\n",
    "        \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        \"content\": results\n",
    "    })\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the youtube analytic Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, show me all cities?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT DISTINCT City_name FROM raw_cities\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT Album_name, COUNT(Track_name) as Track_count FROM music_album GROUP BY Album_name ORDER BY Track_count DESC LIMIT 1\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the cities that start ET?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT City_name FROM raw_cities WHERE City_name LIKE \\'ET%\\'\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"What is the name of the cities that start ET?\"})\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "assistant_message['content'] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'], \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"], \"content\": results})\n",
    "pretty_print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the youtube analytic Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, show me all cities?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT DISTINCT City_name FROM raw_cities\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT Album_name, COUNT(Track_name) as Track_count FROM music_album GROUP BY Album_name ORDER BY Track_count DESC LIMIT 1\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the cities that start ET?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT City_name FROM raw_cities WHERE City_name LIKE \\'ET%\\'\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n",
      "\u001b[32muser: What are the avrage view per day?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT AVG(RollingAverageViews) as Average_views_per_day FROM dim_dail_view_7day\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): []\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"What are the avrage view per day?\"})\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "assistant_message['content'] = str(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'], \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"], \"content\": results})\n",
    "pretty_print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
