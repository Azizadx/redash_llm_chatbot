{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is just a sample code so that you can understand how to use function calling it not a starter code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json \n",
    "import requests\n",
    "from pprint import pprint\n",
    "import tiktoken\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the example below LLM acts as an intermediary that translates a user's natural language request into a structured SQL query, which is then executed by a database tool to fetch and return the relevant data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gcp \n",
    "_SCOPE = 'https://www.googleapis.com/auth/cloud-platform'\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client.from_service_account_json('../../data_warehousing/data_warehousing/include/gcp/service_account.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if tools is not None:\n",
    "        json_data.update({\"tools\": tools})\n",
    "    if tool_choice is not None:\n",
    "        json_data.update({\"tool_choice\": tool_choice})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "def get_gpt_response(system_message, user_message):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"tool\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"tool\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_table_names(client, dataset_id):\n",
    "    \"\"\"Return a list of table names in the specified dataset.\"\"\"\n",
    "    table_names = []\n",
    "    dataset_ref = client.dataset(dataset_id)\n",
    "    # List tables in the dataset\n",
    "    tables = client.list_tables(dataset_ref)\n",
    "    for table in tables:\n",
    "        table_names.append(table.table_id)\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(client, dataset_id, table_name):\n",
    "    \"\"\"Return a list of column names for the specified table.\"\"\"\n",
    "    column_names = []\n",
    "    table_ref = client.dataset(dataset_id).table(table_name)\n",
    "    table = client.get_table(table_ref)\n",
    "    for field in table.schema:\n",
    "        column_names.append(field.name)\n",
    "    return column_names\n",
    "\n",
    "def get_database_info(client, dataset_id):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the dataset.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(client, dataset_id):\n",
    "        column_names = get_column_names(client, dataset_id, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": column_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(client,'youtube')\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: dim_dail_view_7day\n",
      "Columns: Date, RollingAverageViews\n",
      "Table: dim_top10\n",
      "Columns: Date, TotalViews\n",
      "Table: raw_cities\n",
      "Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
      "Table: raw_gender\n",
      "Columns: Date, Views, Watch_time__hours_, Average_view_duration\n",
      "Table: raw_total\n",
      "Columns: Date, Views\n"
     ]
    }
   ],
   "source": [
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = \"\"\"\n",
    "# General Analysis Queries\n",
    "1. \"What are the most significant trends in viewership data over the past month? Consider views, watch time, and average view duration across different tables.\"\n",
    "2. \"Identify the top-performing videos in the last quarter based on data from the dim_top10 table.\"\n",
    "...\n",
    "\n",
    "# Specific Data Requests\n",
    "3. \"Provide a breakdown of views, watch time, and average view duration by device type for the past week, using data from raw_total and raw_gender tables.\"\n",
    "4. \"Show me the top 5 traffic sources driving the most views to the channel based on available data.\"\n",
    "...\n",
    "\n",
    "# SQL Query Generation\n",
    "5. \"Generate an SQL query to retrieve specific data points from specified tables. Clearly state the desired data points and conditions.\"\n",
    "6. \"Translate this natural language question into an SQL query: [Ask your question in plain English, specifying relevant tables].\"\n",
    "...\n",
    "\n",
    "# Data Clarification\n",
    "7. \"Could you please clarify what you mean by X, and which tables or columns are relevant to your query?\"\n",
    "8. \"Provide an example of what you're looking for, specifying the tables and columns you'd like to focus on.\"\n",
    "...\n",
    "\n",
    "# Uncertainty Handling\n",
    "9. \"I'm not confident in providing an accurate answer to that question based on available data. Would you like me to generate an approximate response or seek further input?\"\n",
    "10. \"I'm unable to generate a query for that question due to ambiguity or potential data limitations. Could you please rephrase it or provide more specific details, including relevant tables and columns?\"\n",
    "...\n",
    "\n",
    "# Additional Tables and Descriptions\n",
    "- youtube.dim_dail_view_7day: Daily Views Trend (7-Day Rolling Average)\n",
    "  Columns: Date, RollingAverageViews\n",
    "  Example Table Data: 2020-09-02 18.857142857142858\n",
    "\n",
    "- youtube.dim_top10: Top 10 Days by Views\n",
    "  Columns: Date, TotalViews\n",
    "  Example Table Data: 2022-08-09 311\n",
    "\n",
    "- youtube.raw_cities: List of all cities\n",
    "  Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
    " Example Table Data:\n",
    "    - 0x164b85cef5ab402d:0x8467b6b Addis Ababa, ET, ET-AA, 1252, 127.5042, 00:06:06\n",
    "\n",
    "- youtube.raw_total: Total views by daily Date column is in this format yyy-mm-dd\n",
    "  Columns: Date, Views\n",
    "  Example Table Data: 2020-07-10 0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"ask_database\",\n",
    "            \"description\": \"Use this function to answer user questions about youtube. Input should be a fully formed SQL query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": f\"\"\"\n",
    "                                \n",
    "                                SQL query extracting info to answer the user's question.\n",
    "                                SQL should be written using this database schema:\n",
    "                                {database_schema_string}\n",
    "                                The query should be returned in plain text, not in JSON.\n",
    "                                \"\"\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "<prompts>\n",
    "{prompts}\n",
    "</prompts>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_token(input, model_name=GPT_MODEL, debug=False):\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        codex = \" \".join(input.splitlines())  # Join lines into a single string\n",
    "        num_tokens = len(encoding.encode(codex))\n",
    "        return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_token(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_database(client, query):\n",
    "    \"\"\"Function to query BigQuery dataset with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "        rows = [row.values() for row in results]\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "        rows = []\n",
    "    return rows\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"tool_calls\"][0][\"function\"][\"name\"] == \"ask_database\":\n",
    "        query = json.loads(message[\"tool_calls\"][0][\"function\"][\"arguments\"])[\"query\"]\n",
    "        results = ask_database(client, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message['tool_calls'][0]['function']['name']} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Conversation ===================\n",
      "\u001b[31msystem: \n",
      "<prompts>\n",
      "\n",
      "# General Analysis Queries\n",
      "1. \"What are the most significant trends in viewership data over the past month? Consider views, watch time, and average view duration across different tables.\"\n",
      "2. \"Identify the top-performing videos in the last quarter based on data from the dim_top10 table.\"\n",
      "...\n",
      "\n",
      "# Specific Data Requests\n",
      "3. \"Provide a breakdown of views, watch time, and average view duration by device type for the past week, using data from raw_total and raw_gender tables.\"\n",
      "4. \"Show me the top 5 traffic sources driving the most views to the channel based on available data.\"\n",
      "...\n",
      "\n",
      "# SQL Query Generation\n",
      "5. \"Generate an SQL query to retrieve specific data points from specified tables. Clearly state the desired data points and conditions.\"\n",
      "6. \"Translate this natural language question into an SQL query: [Ask your question in plain English, specifying relevant tables].\"\n",
      "...\n",
      "\n",
      "# Data Clarification\n",
      "7. \"Could you please clarify what you mean by X, and which tables or columns are relevant to your query?\"\n",
      "8. \"Provide an example of what you're looking for, specifying the tables and columns you'd like to focus on.\"\n",
      "...\n",
      "\n",
      "# Uncertainty Handling\n",
      "9. \"I'm not confident in providing an accurate answer to that question based on available data. Would you like me to generate an approximate response or seek further input?\"\n",
      "10. \"I'm unable to generate a query for that question due to ambiguity or potential data limitations. Could you please rephrase it or provide more specific details, including relevant tables and columns?\"\n",
      "...\n",
      "\n",
      "# Additional Tables and Descriptions\n",
      "- youtube.dim_dail_view_7day: Daily Views Trend (7-Day Rolling Average)\n",
      "  Columns: Date, RollingAverageViews\n",
      "  Example Table Data: 2020-09-02 18.857142857142858\n",
      "\n",
      "- youtube.dim_top10: Top 10 Days by Views\n",
      "  Columns: Date, TotalViews\n",
      "  Example Table Data: 2022-08-09 311\n",
      "\n",
      "- youtube.raw_cities: List of all cities\n",
      "  Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
      " Example Table Data:\n",
      "    - 0x164b85cef5ab402d:0x8467b6b Addis Ababa, ET, ET-AA, 1252, 127.5042, 00:06:06\n",
      "\n",
      "- youtube.raw_total: Total views by daily Date column is in this format yyy-mm-dd\n",
      "  Columns: Date, Views\n",
      "  Example Table Data: 2020-07-10 0\n",
      "\n",
      "\n",
      "</prompts>\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, What are the top 5 cities?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: To determine the top 5 cities based on a specific metric such as views or watch time, we would need to run a query on the `youtube.raw_cities` table. However, since you haven't specified the metric, I will assume you are asking for the top 5 cities by views. Here's an example of an SQL query that would retrieve this information:\n",
      "\n",
      "```sql\n",
      "SELECT City_name, SUM(Views) AS TotalViews\n",
      "FROM youtube.raw_cities\n",
      "GROUP BY City_name\n",
      "ORDER BY TotalViews DESC\n",
      "LIMIT 5;\n",
      "```\n",
      "\n",
      "This query will sum up the views for each city, group the results by the city name, order them in descending order by the total views, and limit the output to the top 5 cities. If you need the top cities by a different metric, such as watch time, you would replace `SUM(Views)` with `SUM(Watch_time__hours_)` in the query.\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [(None, 26625), ('Addis Ababa', 1252), ('Manchester', 23), ('Busan', 14), ('Khartoum', 12)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Hi, What are the top 5 cities?\"\n",
    "\n",
    "# Messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Get GPT response\n",
    "gpt_response = get_gpt_response(system_message, user_message)\n",
    "\n",
    "# Add GPT response to messages\n",
    "messages.append({\"role\": \"assistant\", \"content\": gpt_response})\n",
    "\n",
    "# Assuming chat_completion_request returns a response with tool calls\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "\n",
    "# Extract assistant's message\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Uncomment the following lines to print the tool call content\n",
    "# print(\"=================== Tool Call Content ===================\")\n",
    "# print(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "\n",
    "# Execute the tool function call\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'],\n",
    "        \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        \"content\": results\n",
    "    })\n",
    "\n",
    "# Print the conversation\n",
    "print(\"=================== Conversation ===================\")\n",
    "pretty_print_conversation(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Conversation ===================\n",
      "\u001b[31msystem: \n",
      "<prompts>\n",
      "\n",
      "# General Analysis Queries\n",
      "1. \"What are the most significant trends in viewership data over the past month? Consider views, watch time, and average view duration across different tables.\"\n",
      "2. \"Identify the top-performing videos in the last quarter based on data from the dim_top10 table.\"\n",
      "...\n",
      "\n",
      "# Specific Data Requests\n",
      "3. \"Provide a breakdown of views, watch time, and average view duration by device type for the past week, using data from raw_total and raw_gender tables.\"\n",
      "4. \"Show me the top 5 traffic sources driving the most views to the channel based on available data.\"\n",
      "...\n",
      "\n",
      "# SQL Query Generation\n",
      "5. \"Generate an SQL query to retrieve specific data points from specified tables. Clearly state the desired data points and conditions.\"\n",
      "6. \"Translate this natural language question into an SQL query: [Ask your question in plain English, specifying relevant tables].\"\n",
      "...\n",
      "\n",
      "# Data Clarification\n",
      "7. \"Could you please clarify what you mean by X, and which tables or columns are relevant to your query?\"\n",
      "8. \"Provide an example of what you're looking for, specifying the tables and columns you'd like to focus on.\"\n",
      "...\n",
      "\n",
      "# Uncertainty Handling\n",
      "9. \"I'm not confident in providing an accurate answer to that question based on available data. Would you like me to generate an approximate response or seek further input?\"\n",
      "10. \"I'm unable to generate a query for that question due to ambiguity or potential data limitations. Could you please rephrase it or provide more specific details, including relevant tables and columns?\"\n",
      "...\n",
      "\n",
      "# Additional Tables and Descriptions\n",
      "- youtube.dim_dail_view_7day: Daily Views Trend (7-Day Rolling Average)\n",
      "  Columns: Date, RollingAverageViews\n",
      "  Example Table Data: 2020-09-02 18.857142857142858\n",
      "\n",
      "- youtube.dim_top10: Top 10 Days by Views\n",
      "  Columns: Date, TotalViews\n",
      "  Example Table Data: 2022-08-09 311\n",
      "\n",
      "- youtube.raw_cities: List of all cities\n",
      "  Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
      " Example Table Data:\n",
      "    - 0x164b85cef5ab402d:0x8467b6b Addis Ababa, ET, ET-AA, 1252, 127.5042, 00:06:06\n",
      "\n",
      "- youtube.raw_total: Total views by daily Date column is in this format yyy-mm-dd\n",
      "  Columns: Date, Views\n",
      "  Example Table Data: 2020-07-10 0\n",
      "\n",
      "\n",
      "</prompts>\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the citie with Geography that equal to ET?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: To find the name of the city with the Geography code \"ET\" in the `youtube.raw_cities` table, you would look for the `City_name` where the `Geography` column equals \"ET\". Here's an example of an SQL query that would retrieve this information:\n",
      "\n",
      "```sql\n",
      "SELECT City_name\n",
      "FROM youtube.raw_cities\n",
      "WHERE Geography = 'ET';\n",
      "```\n",
      "\n",
      "This query will return the name of the city or cities that have the Geography code \"ET\". If you are looking for a specific Geography level such as \"ET-AA\", you would need to adjust the `WHERE` clause accordingly.\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Addis Ababa',)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the name of the citie with Geography that equal to ET?\"\n",
    "\n",
    "# Messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Get GPT response\n",
    "gpt_response = get_gpt_response(system_message, user_message)\n",
    "\n",
    "# Add GPT response to messages\n",
    "messages.append({\"role\": \"assistant\", \"content\": gpt_response})\n",
    "\n",
    "# Assuming chat_completion_request returns a response with tool calls\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "\n",
    "# Extract assistant's message\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Uncomment the following lines to print the tool call content\n",
    "# print(\"=================== Tool Call Content ===================\")\n",
    "# print(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "\n",
    "# Execute the tool function call\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'],\n",
    "        \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        \"content\": results\n",
    "    })\n",
    "\n",
    "# Print the conversation\n",
    "print(\"=================== Conversation ===================\")\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Conversation ===================\n",
      "\u001b[31msystem: \n",
      "<prompts>\n",
      "\n",
      "# General Analysis Queries\n",
      "1. \"What are the most significant trends in viewership data over the past month? Consider views, watch time, and average view duration across different tables.\"\n",
      "2. \"Identify the top-performing videos in the last quarter based on data from the dim_top10 table.\"\n",
      "...\n",
      "\n",
      "# Specific Data Requests\n",
      "3. \"Provide a breakdown of views, watch time, and average view duration by device type for the past week, using data from raw_total and raw_gender tables.\"\n",
      "4. \"Show me the top 5 traffic sources driving the most views to the channel based on available data.\"\n",
      "...\n",
      "\n",
      "# SQL Query Generation\n",
      "5. \"Generate an SQL query to retrieve specific data points from specified tables. Clearly state the desired data points and conditions.\"\n",
      "6. \"Translate this natural language question into an SQL query: [Ask your question in plain English, specifying relevant tables].\"\n",
      "...\n",
      "\n",
      "# Data Clarification\n",
      "7. \"Could you please clarify what you mean by X, and which tables or columns are relevant to your query?\"\n",
      "8. \"Provide an example of what you're looking for, specifying the tables and columns you'd like to focus on.\"\n",
      "...\n",
      "\n",
      "# Uncertainty Handling\n",
      "9. \"I'm not confident in providing an accurate answer to that question based on available data. Would you like me to generate an approximate response or seek further input?\"\n",
      "10. \"I'm unable to generate a query for that question due to ambiguity or potential data limitations. Could you please rephrase it or provide more specific details, including relevant tables and columns?\"\n",
      "...\n",
      "\n",
      "# Additional Tables and Descriptions\n",
      "- youtube.dim_dail_view_7day: Daily Views Trend (7-Day Rolling Average)\n",
      "  Columns: Date, RollingAverageViews\n",
      "  Example Table Data: 2020-09-02 18.857142857142858\n",
      "\n",
      "- youtube.dim_top10: Top 10 Days by Views\n",
      "  Columns: Date, TotalViews\n",
      "  Example Table Data: 2022-08-09 311\n",
      "\n",
      "- youtube.raw_cities: List of all cities\n",
      "  Columns: Cities, City_name, Geography, Geography_3, Views, Watch_time__hours_, Average_view_duration\n",
      " Example Table Data:\n",
      "    - 0x164b85cef5ab402d:0x8467b6b Addis Ababa, ET, ET-AA, 1252, 127.5042, 00:06:06\n",
      "\n",
      "- youtube.raw_total: Total views by daily Date column is in this format yyy-mm-dd\n",
      "  Columns: Date, Views\n",
      "  Example Table Data: 2020-07-10 0\n",
      "\n",
      "\n",
      "</prompts>\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: What are the average view per day?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: To calculate the average views per day, you would typically sum up all the views over a certain period and then divide by the number of days in that period. If you're looking to perform this calculation using SQL on a table that records daily views, you would use the `AVG` aggregate function.\n",
      "\n",
      "Assuming you have a table like `youtube.raw_total` which has a `Date` column and a `Views` column, the SQL query would look something like this:\n",
      "\n",
      "```sql\n",
      "SELECT AVG(Views) AS AverageViewsPerDay\n",
      "FROM youtube.raw_total;\n",
      "```\n",
      "\n",
      "This query would give you the average number of views per day across all the days recorded in the `youtube.raw_total` table. If you want to calculate the average for a specific time range, you would add a `WHERE` clause to filter the dates accordingly.\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [(20.810007818608277,)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What are the average view per day?\"\n",
    "\n",
    "# Messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Get GPT response\n",
    "gpt_response = get_gpt_response(system_message, user_message)\n",
    "\n",
    "# Add GPT response to messages\n",
    "messages.append({\"role\": \"assistant\", \"content\": gpt_response})\n",
    "\n",
    "# Assuming chat_completion_request returns a response with tool calls\n",
    "chat_response = chat_completion_request(messages, tools)\n",
    "\n",
    "# Extract assistant's message\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Uncomment the following lines to print the tool call content\n",
    "# print(\"=================== Tool Call Content ===================\")\n",
    "# print(assistant_message[\"tool_calls\"][0][\"function\"])\n",
    "\n",
    "# Execute the tool function call\n",
    "if assistant_message.get(\"tool_calls\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": assistant_message[\"tool_calls\"][0]['id'],\n",
    "        \"name\": assistant_message[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        \"content\": results\n",
    "    })\n",
    "\n",
    "# Print the conversation\n",
    "print(\"=================== Conversation ===================\")\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
